{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8042b4",
   "metadata": {},
   "source": [
    "# Final version that works on all operating systems with images and videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d17455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766169652.288339  111825 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1 Max\n",
      "W0000 00:00:1766169652.353844  352481 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766169652.397496  352481 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Processing video...\n",
      "‚è≥ Frame 180\n",
      "‚úÖ Video written: /Users/marcbp/spiced_bootcamp/Capstone Project/GAITy-Capstone-Modeling/notebooks/../data/output/annotated_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# MediaPipe PoseLandmarker\n",
    "# Works with images OR videos\n",
    "# Cross-platform + notebook-safe\n",
    "# -------------------------------------------------------\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# BASE DIRECTORY (safe for script & notebook)\n",
    "# ----------------------------\n",
    "if \"__file__\" in globals():\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "else:\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG  (CHANGE THESE)\n",
    "# ----------------------------\n",
    "INPUT_PATH = BASE_DIR / \"../data/videos/video.mp4\"   # <-- image OR video ---  change file name\n",
    "MODEL_PATH = BASE_DIR / \"../models/pose_landmarker_heavy.task\" # <--- change model \n",
    "\n",
    "OUT_DIR = BASE_DIR / \"../data/output\" #<---- output dir\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# FILE TYPE DETECTION\n",
    "# ----------------------------\n",
    "INPUT_PATH = INPUT_PATH.resolve()\n",
    "ext = INPUT_PATH.suffix.lower()\n",
    "\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\"}\n",
    "\n",
    "if ext in IMAGE_EXTS:\n",
    "    MODE = \"image\"\n",
    "elif ext in VIDEO_EXTS:\n",
    "    MODE = \"video\"\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "# ----------------------------\n",
    "# OUTPUT PATHS\n",
    "# ----------------------------\n",
    "OUT_IMAGE = OUT_DIR / \"annotated_image.png\" #<---- name of annotated output image\n",
    "OUT_VIDEO = OUT_DIR / \"annotated_video.mp4\" # <---- name of annotated output video\n",
    "OUT_CSV   = OUT_DIR / \"pose_landmarks.csv\" # <----- name of ouput csv data with landmarks\n",
    "\n",
    "# ----------------------------\n",
    "# OS DETECTION + CODEC\n",
    "# ----------------------------\n",
    "system = platform.system()\n",
    "\n",
    "# IMPORTANT: mp4v works on Windows/macOS/Linux\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: PoseLandmarker\n",
    "# ----------------------------\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=str(MODEL_PATH))\n",
    "\n",
    "if MODE == \"image\":\n",
    "    options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        running_mode=vision.RunningMode.IMAGE,\n",
    "        output_segmentation_masks=False,\n",
    "    )\n",
    "else:\n",
    "    options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        running_mode=vision.RunningMode.VIDEO,\n",
    "        output_segmentation_masks=False,\n",
    "    )\n",
    "\n",
    "detector = vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: CSV writer\n",
    "# ----------------------------\n",
    "csv_file = open(OUT_CSV, \"w\", newline=\"\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "csv_writer.writerow([\n",
    "    \"frame\",\n",
    "    \"timestamp_ms\",\n",
    "    \"landmark_id\",\n",
    "    \"x_norm\",\n",
    "    \"y_norm\",\n",
    "    \"z_norm\",\n",
    "    \"visibility\",\n",
    "    \"x_px\",\n",
    "    \"y_px\",\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# COLORS (RGB)\n",
    "# ----------------------------\n",
    "LANDMARK_COLOR = (0, 255, 0)\n",
    "CONNECTION_COLOR = (255, 0, 0)\n",
    "\n",
    "# ======================================================\n",
    "# IMAGE MODE\n",
    "# ======================================================\n",
    "if MODE == \"image\":\n",
    "    print(\"üñº Processing image...\")\n",
    "\n",
    "    frame = cv2.imread(str(INPUT_PATH))\n",
    "    if frame is None:\n",
    "        raise RuntimeError(\"Could not read image\")\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=frame_rgb\n",
    "    )\n",
    "\n",
    "    result = detector.detect(mp_image)\n",
    "    annotated_rgb = frame_rgb.copy()\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        pose_landmarks = result.pose_landmarks[0]\n",
    "\n",
    "        for lm_id, lm in enumerate(pose_landmarks):\n",
    "            csv_writer.writerow([\n",
    "                0, 0, lm_id,\n",
    "                lm.x, lm.y, lm.z, lm.visibility,\n",
    "                int(lm.x * width), int(lm.y * height)\n",
    "            ])\n",
    "\n",
    "        pose_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(\n",
    "                x=lm.x, y=lm.y, z=lm.z\n",
    "            ) for lm in pose_landmarks\n",
    "        ])\n",
    "\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_rgb,\n",
    "            pose_proto,\n",
    "            mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "                color=LANDMARK_COLOR, thickness=2, circle_radius=2\n",
    "            ),\n",
    "            connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "                color=CONNECTION_COLOR, thickness=2\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    annotated_bgr = cv2.cvtColor(annotated_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(str(OUT_IMAGE), annotated_bgr)\n",
    "\n",
    "    output_path = OUT_IMAGE\n",
    "    print(\"‚úÖ Image written:\", OUT_IMAGE)\n",
    "\n",
    "# ======================================================\n",
    "# VIDEO MODE\n",
    "# ======================================================\n",
    "else:\n",
    "    print(\"üé¨ Processing video...\")\n",
    "\n",
    "    cap = cv2.VideoCapture(str(INPUT_PATH))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open video\")\n",
    "\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps <= 0:\n",
    "        fps = 30.0\n",
    "\n",
    "    writer = cv2.VideoWriter(\n",
    "        str(OUT_VIDEO),\n",
    "        fourcc,\n",
    "        fps,\n",
    "        (width, height)\n",
    "    )\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=frame_rgb\n",
    "        )\n",
    "\n",
    "        timestamp_ms = int((frame_idx / fps) * 1000)\n",
    "        result = detector.detect_for_video(mp_image, timestamp_ms)\n",
    "        annotated_rgb = frame_rgb.copy()\n",
    "\n",
    "        if result.pose_landmarks:\n",
    "            pose_landmarks = result.pose_landmarks[0]\n",
    "\n",
    "            for lm_id, lm in enumerate(pose_landmarks):\n",
    "                csv_writer.writerow([\n",
    "                    frame_idx, timestamp_ms, lm_id,\n",
    "                    lm.x, lm.y, lm.z, lm.visibility,\n",
    "                    int(lm.x * width), int(lm.y * height)\n",
    "                ])\n",
    "\n",
    "            pose_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            pose_proto.landmark.extend([\n",
    "                landmark_pb2.NormalizedLandmark(\n",
    "                    x=lm.x, y=lm.y, z=lm.z\n",
    "                ) for lm in pose_landmarks\n",
    "            ])\n",
    "\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                annotated_rgb,\n",
    "                pose_proto,\n",
    "                mp.solutions.pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "                    color=LANDMARK_COLOR, thickness=2, circle_radius=2\n",
    "                ),\n",
    "                connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "                    color=CONNECTION_COLOR, thickness=2\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        annotated_bgr = cv2.cvtColor(annotated_rgb, cv2.COLOR_RGB2BGR)\n",
    "        writer.write(annotated_bgr)\n",
    "\n",
    "        if frame_idx % 30 == 0:\n",
    "            print(f\"\\r‚è≥ Frame {frame_idx}\", end=\"\")\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    output_path = OUT_VIDEO\n",
    "    print(\"\\n‚úÖ Video written:\", OUT_VIDEO)\n",
    "\n",
    "# ----------------------------\n",
    "# CLEANUP\n",
    "# ----------------------------\n",
    "csv_file.close()\n",
    "\n",
    "# ----------------------------\n",
    "# AUTO OPEN OUTPUT (WORKS ON WINDOWS) - Disable if no output is desired\n",
    "# ----------------------------\n",
    "if output_path.exists():\n",
    "    try:\n",
    "        if system == \"Windows\":\n",
    "            os.startfile(output_path)\n",
    "        elif system == \"Darwin\":\n",
    "            subprocess.run([\"open\", str(output_path)])\n",
    "        elif system == \"Linux\":\n",
    "            subprocess.run([\"xdg-open\", str(output_path)])\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Could not auto-open file:\", e)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Output file not found:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefc67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
